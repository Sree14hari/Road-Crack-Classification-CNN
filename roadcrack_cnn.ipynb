{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1QEFW-G-fwbUyhs5nO0LNIDbCoEwLO4d4",
      "authorship_tag": "ABX9TyPAuZTRkc49JJ8USA2irHkB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sree14hari/Road-Crack-Classification-CNN/blob/main/roadcrack_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smpOF6d5qiVC"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "# Install the rarfile library\n",
        "!pip install rarfile\n",
        "\n",
        "import rarfile\n",
        "\n",
        "# --- YOU NEED TO UPDATE THIS PATH ---\n",
        "# Path to your zipped dataset in Google Drive or Colab environment\n",
        "rar_file_path = '/content/drive/MyDrive/Augmented_Dataset.rar'\n",
        "# ------------------------------------\n",
        "\n",
        "# Directory to extract the files to in the Colab environment\n",
        "extract_path = '/content/dataset'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(extract_path):\n",
        "    os.makedirs(extract_path)\n",
        "\n",
        "print(f\"Unzipping {rar_file_path} to {extract_path}...\")\n",
        "try:\n",
        "    with rarfile.RarFile(rar_file_path, 'r') as rf:\n",
        "        rf.extractall(extract_path)\n",
        "    print(\"Unzipping complete! âœ…\")\n",
        "except rarfile.Error as e:\n",
        "    print(f\"Error unzipping RAR file: {e}\")\n",
        "\n",
        "\n",
        "# Let's verify the contents\n",
        "print(\"\\nContents of the extracted folder:\")\n",
        "# Note: Adjust the folder name if the unzipping creates a different parent folder.\n",
        "# You might need to inspect the extracted directory structure to find the correct path\n",
        "extracted_content_path = extract_path # Start by listing the top-level extracted directory\n",
        "\n",
        "if os.path.exists(extracted_content_path):\n",
        "    print(os.listdir(extracted_content_path))\n",
        "else:\n",
        "    print(f\"Extracted path {extracted_content_path} not found.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. SETUP: Define Paths and Parameters ---\n",
        "# Path to the extracted dataset in Colab\n",
        "base_dir = '/content/dataset/Augmented_Dataset'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20 # Start with 20 epochs\n",
        "NUM_CLASSES = 4\n",
        "\n",
        "# --- 2. DATA PREPARATION: Create Data Generators ---\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# --- 3. MODEL BUILDING: Use Transfer Learning with VGG16 ---\n",
        "# Load the VGG16 base model, pre-trained on ImageNet\n",
        "base_model = VGG16(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
        "                   include_top=False, # Don't include the final ImageNet classifier\n",
        "                   weights='imagenet')\n",
        "\n",
        "# Freeze the layers of the base model so they are not re-trained\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create your new model on top of the base model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5), # Regularization\n",
        "    Dense(NUM_CLASSES, activation='softmax') # Your final output layer\n",
        "])\n",
        "\n",
        "# --- 4. MODEL COMPILATION ---\n",
        "# Use a lower learning rate for fine-tuning\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# --- 5. TRAINING ---\n",
        "print(\"\\nStarting model training...\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "print(\"Training finished!\")\n",
        "\n",
        "# --- 6. VISUALIZATION ---\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "# --- 7. EVALUATION ---\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"\\nEvaluating on test data...\")\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_acc*100:.2f}%\")"
      ],
      "metadata": {
        "id": "rxX976Epr034"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7faf828b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Get the true labels from the test generator\n",
        "test_labels = test_generator.classes\n",
        "\n",
        "# Get the predicted labels from the model\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get the class names from the generator\n",
        "class_names = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(test_labels, predicted_labels)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Generate the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_labels, predicted_labels, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}